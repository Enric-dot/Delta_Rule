{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "En este colab se va a extraer un a funcion de optimizacion para la variable **w** de la siguiente equacion:\n",
        "\n",
        "**e = Re - (w*x)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0WXeNL-Rus4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis de funcion:\n",
        "\n",
        "        **e = Re - (w*x)**\n",
        "        Leyenda:\n",
        "            *e -> error\n",
        "            *Re ->resultado esperado\n",
        "            *w -> peso\n",
        "            *x -> input\n",
        "\n",
        "\n",
        "Tabla de verdad de la funcion se hara una tabla en la que consideremos que todo son constantes excepto w y veremos como evoluciona la funcion teniendo en cuenta que queremos que el error se aproxime a 0:\n",
        "\n",
        "    e      x      (w+1)\n",
        "    -      -      queremos que aumente paraque e se aproxime a 0\n",
        "    -      +      queremos que disminya para aproximar e a 0\n",
        "    +      -      queremos que disminya para aproximar e a 0\n",
        "    +      +      queremos que aumente paraque e se aproxime a 0\n",
        "\n",
        "** Date cuenta de que Re no importa si es positivo o negativo aunque cambies el signo de Re sin cambier el signo de x y de e la evolucion que necesitamos de w es la misma\n",
        "\n",
        "Ej\n",
        "\n",
        "En este ejemplo si aumentamos w el error cada vez sera mas negativo y nos alejaremos del 0\n",
        "\n",
        "Si disminuimos w cada vez sera menos negativo y el error se ira hacercando al 0\n",
        "\n",
        "-0.4 = 1-(1*w)\n",
        "\n",
        "Si cambiamos el error es positivo queremos que w en vez de disminuir aumente\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JBDT7OWDtqZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez hecho el analisis queremos diseñar una funcion que cumpla nuestra tabla de verdad:\n",
        "\n",
        "\n",
        "    e      x      Resultado que queremos\n",
        "    -      -      +\n",
        "    -      +      -\n",
        "    +      -      -\n",
        "    +      +      +\n",
        "\n",
        "El resultado de la equacion se debera añadir a w para su siguiente iteración\n",
        "\n",
        "w = w + (e * x)"
      ],
      "metadata": {
        "id": "3to7jr2wzgmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "dM20EC3i6ZtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6YaxzHmtmpR"
      },
      "outputs": [],
      "source": [
        "def delta_rule(e : float, x : float, w : float, lr : float = 0.002 ):\n",
        "  '''\n",
        "  Regla optimización que actualiza w\n",
        "  Params\n",
        "      e-> error de la iteracion previa\n",
        "      x -> input\n",
        "      w-> peso de la iteracion pervia\n",
        "      lr-> learning rate\n",
        "  resultado\n",
        "      wt-> la nueva version de w\n",
        "\n",
        "  '''\n",
        "\n",
        "  return w+lr*e*x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(Re: float, x: float, w:float):\n",
        "  '''\n",
        "  Funcion de calculo de perdida\n",
        "  Params\n",
        "      Re-> resultado esperado\n",
        "      x -> input\n",
        "      w-> peso de la iteracion pervia\n",
        "  resultado\n",
        "      e-> error de la iteracion previa\n",
        "\n",
        "  '''\n",
        "  return Re-(x*w)"
      ],
      "metadata": {
        "id": "q3ZBhlot2hQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimization(epochs : int , x: float, Re: float):\n",
        "  '''\n",
        "  Funcion que aplica la regla de optimizacion y aproxima el error a 0\n",
        "  Params\n",
        "      epochs-> la cantidad de iteraciones que quiero aplicar al algoritmo\n",
        "      x -> input\n",
        "      Re-> resultado esperado\n",
        "\n",
        "  '''\n",
        "  w = random.uniform(0, 1)\n",
        "  print('Initialization weight: ',w )\n",
        "  for i in range(epochs):\n",
        "    e = loss(Re,x,w)\n",
        "    w = delta_rule(e,x,w)\n",
        "    print('Error: ',e, ' Weight: ',w )\n"
      ],
      "metadata": {
        "id": "5c707IAU4ILJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimization(epochs = 40,x = 2,Re = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HjoTU3C63rq",
        "outputId": "9549dae7-49ce-474e-ef35-9d1b16650c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization weight:  0.768948195754644\n",
            "Error:  0.46210360849071197  Weight:  0.7707966101886069\n",
            "Error:  0.4584067796227862  Weight:  0.772630237307098\n",
            "Error:  0.454739525385804  Weight:  0.7744491954086412\n",
            "Error:  0.4511016091827176  Weight:  0.7762536018453721\n",
            "Error:  0.44749279630925587  Weight:  0.7780435730306091\n",
            "Error:  0.44391285393878177  Weight:  0.7798192244463642\n",
            "Error:  0.4403615511072716  Weight:  0.7815806706507933\n",
            "Error:  0.43683865869841343  Weight:  0.783328025285587\n",
            "Error:  0.43334394942882604  Weight:  0.7850614010833022\n",
            "Error:  0.4298771978333955  Weight:  0.7867809098746358\n",
            "Error:  0.42643818025072844  Weight:  0.7884866625956387\n",
            "Error:  0.4230266748087226  Weight:  0.7901787692948736\n",
            "Error:  0.41964246141025274  Weight:  0.7918573391405146\n",
            "Error:  0.4162853217189708  Weight:  0.7935224804273905\n",
            "Error:  0.412955039145219  Weight:  0.7951743005839713\n",
            "Error:  0.40965139883205737  Weight:  0.7968129061792996\n",
            "Error:  0.4063741876414009  Weight:  0.7984384029298651\n",
            "Error:  0.40312319414026976  Weight:  0.8000508957064262\n",
            "Error:  0.39989820858714764  Weight:  0.8016504885407748\n",
            "Error:  0.3966990229184504  Weight:  0.8032372846324486\n",
            "Error:  0.3935254307351028  Weight:  0.804811386355389\n",
            "Error:  0.3903772272892221  Weight:  0.8063728952645458\n",
            "Error:  0.3872542094709084  Weight:  0.8079219121024295\n",
            "Error:  0.38415617579514105  Weight:  0.8094585368056101\n",
            "Error:  0.38108292638877983  Weight:  0.8109828685111652\n",
            "Error:  0.3780342629776696  Weight:  0.8124950055630759\n",
            "Error:  0.3750099888738483  Weight:  0.8139950455185713\n",
            "Error:  0.37200990896285746  Weight:  0.8154830851544227\n",
            "Error:  0.3690338296911546  Weight:  0.8169592204731874\n",
            "Error:  0.36608155905362527  Weight:  0.8184235467094019\n",
            "Error:  0.36315290658119626  Weight:  0.8198761583357267\n",
            "Error:  0.3602476833285466  Weight:  0.8213171490690409\n",
            "Error:  0.3573657018619183  Weight:  0.8227466118764886\n",
            "Error:  0.35450677624702287  Weight:  0.8241646389814766\n",
            "Error:  0.35167072203704675  Weight:  0.8255713218696248\n",
            "Error:  0.34885735626075043  Weight:  0.8269667512946678\n",
            "Error:  0.3460664974106644  Weight:  0.8283510172843105\n",
            "Error:  0.343297965431379  Weight:  0.829724209146036\n",
            "Error:  0.3405515817079281  Weight:  0.8310864154728677\n",
            "Error:  0.3378271690542647  Weight:  0.8324377241490847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delta_rule_multiple(e : float, x : list, w : float, lr : float = 0.002 ):\n",
        "  '''\n",
        "  Regla optimización que actualiza w\n",
        "  Params\n",
        "      e-> error de la iteracion previa\n",
        "      x -> input\n",
        "      w-> peso de la iteracion pervia\n",
        "      lr-> learning rate\n",
        "  resultado\n",
        "      wt-> la nueva version de w\n",
        "\n",
        "  '''\n",
        "  for i in x:\n",
        "    w = w+lr*e*i\n",
        "  return w"
      ],
      "metadata": {
        "id": "Xn9ylGnAIeir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_multiple(Re: list, x: list, w:float):\n",
        "  '''\n",
        "  Funcion de calculo de perdida\n",
        "  Params\n",
        "      Re-> resultado esperado\n",
        "      x -> input\n",
        "      w-> peso de la iteracion pervia\n",
        "  resultado\n",
        "      e-> error de la iteracion previa\n",
        "\n",
        "  '''\n",
        "\n",
        "  return sum([e1-e2*w for e1,e2 in zip(Re,x)])/len(x)"
      ],
      "metadata": {
        "id": "diI1JSieIfeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo para multiples"
      ],
      "metadata": {
        "id": "gXvfd3SnK_Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimization_mltiple(epochs : int , x: list, Re: list):\n",
        "  '''\n",
        "  Funcion que aplica la regla de optimizacion y aproxima el error a 0\n",
        "  Params\n",
        "      epochs-> la cantidad de iteraciones que quiero aplicar al algoritmo\n",
        "      x -> input\n",
        "      Re-> resultado esperado\n",
        "\n",
        "  '''\n",
        "  w = random.uniform(0, 1)\n",
        "  print('Initialization weight: ',w )\n",
        "  for i in range(epochs):\n",
        "    e = loss_multiple(Re,x,w)\n",
        "    w = delta_rule_multiple(e,x,w)\n",
        "    print('Error: ',e, ' Weight: ',w )"
      ],
      "metadata": {
        "id": "xupwgrrJHA6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1,2,3,4,5]\n",
        "outputs = [-2,-4,-6,-8,-10]\n",
        "#x*w Modelo\n",
        "optimization_mltiple(epochs = 100,x = inputs,Re = outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "berBFY0XDdS4",
        "outputId": "bd09f80c-57d4-4ce4-d355-b6a7dfb3581e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization weight:  0.01670676135376692\n",
            "Error:  -6.0501202840613  Weight:  -0.16479684716807208\n",
            "Error:  -5.505609458495784  Weight:  -0.32996513092294566\n",
            "Error:  -5.010104607231163  Weight:  -0.4802682691398806\n",
            "Error:  -4.559195192580358  Weight:  -0.6170441249172913\n",
            "Error:  -4.148867625248125  Weight:  -0.7415101536747352\n",
            "Error:  -3.775469538975795  Weight:  -0.854774239844009\n",
            "Error:  -3.4356772804679734  Weight:  -0.9578445582580483\n",
            "Error:  -3.126466325225855  Weight:  -1.051638548014824\n",
            "Error:  -2.8450843559555277  Weight:  -1.13699107869349\n",
            "Error:  -2.58902676391953  Weight:  -1.2146618816110757\n",
            "Error:  -2.356014355166773  Weight:  -1.2853423122660788\n",
            "Error:  -2.1439730632017637  Weight:  -1.3496615041621316\n",
            "Error:  -1.9510154875136052  Weight:  -1.4081919687875397\n",
            "Error:  -1.7754240936373809  Weight:  -1.461454691596661\n",
            "Error:  -1.6156359252100168  Weight:  -1.5099237693529615\n",
            "Error:  -1.4702286919411156  Weight:  -1.554030630111195\n",
            "Error:  -1.337908109666415  Weight:  -1.5941678734011875\n",
            "Error:  -1.2174963797964375  Weight:  -1.6306927647950806\n",
            "Error:  -1.107921705614758  Weight:  -1.6639304159635233\n",
            "Error:  -1.00820875210943  Weight:  -1.6941766785268062\n",
            "Error:  -0.9174699644195814  Weight:  -1.7217007774593935\n",
            "Error:  -0.8348976676218193  Weight:  -1.746747707488048\n",
            "Error:  -0.7597568775358559  Weight:  -1.7695404138141237\n",
            "Error:  -0.6913787585576285  Weight:  -1.7902817765708525\n",
            "Error:  -0.6291546702874422  Weight:  -1.8091564166794758\n",
            "Error:  -0.5725307499615726  Weight:  -1.826332339178323\n",
            "Error:  -0.5210029824650309  Weight:  -1.841962428652274\n",
            "Error:  -0.47411271404317806  Weight:  -1.8561858100735695\n",
            "Error:  -0.4314425697792914  Weight:  -1.8691290871669484\n",
            "Error:  -0.3926127384991549  Weight:  -1.880907469321923\n",
            "Error:  -0.35727759203423104  Weight:  -1.89162579708295\n",
            "Error:  -0.32512260875115023  Weight:  -1.9013794753454845\n",
            "Error:  -0.29586157396354645  Weight:  -1.910255322564391\n",
            "Error:  -0.26923403230682696  Weight:  -1.918332343533596\n",
            "Error:  -0.245002969399212  Weight:  -1.9256824326155726\n",
            "Error:  -0.22295270215328222  Weight:  -1.9323710136801713\n",
            "Error:  -0.20288695895948633  Weight:  -1.938457622448956\n",
            "Error:  -0.1846271326531319  Weight:  -1.94399643642855\n",
            "Error:  -0.16801069071434993  Weight:  -1.9490367571499805\n",
            "Error:  -0.15288972855005872  Weight:  -1.9536234490064823\n",
            "Error:  -0.13912965298055285  Weight:  -1.9577973385958989\n",
            "Error:  -0.12660798421230351  Weight:  -1.961595578122268\n",
            "Error:  -0.1152132656331959  Weight:  -1.965051976091264\n",
            "Error:  -0.10484407172620806  Weight:  -1.9681972982430502\n",
            "Error:  -0.09540810527084931  Weight:  -1.9710595414011758\n",
            "Error:  -0.08682137579647282  Weight:  -1.97366418267507\n",
            "Error:  -0.07900745197479005  Weight:  -1.9760344062343138\n",
            "Error:  -0.07189678129705875  Weight:  -1.9781913096732255\n",
            "Error:  -0.06542607098032356  Weight:  -1.9801540918026352\n",
            "Error:  -0.05953772459209446  Weight:  -1.9819402235403982\n",
            "Error:  -0.0541793293788055  Weight:  -1.9835656034217624\n",
            "Error:  -0.04930318973471293  Weight:  -1.9850446991138038\n",
            "Error:  -0.044865902658588516  Weight:  -1.9863906761935615\n",
            "Error:  -0.04082797141931578  Weight:  -1.987615515336141\n",
            "Error:  -0.03715345399157699  Weight:  -1.9887301189558884\n",
            "Error:  -0.03380964313233492  Weight:  -1.9897444082498585\n",
            "Error:  -0.03076677525042455  Weight:  -1.9906674115073713\n",
            "Error:  -0.02799776547788624  Weight:  -1.9915073444717077\n",
            "Error:  -0.025477966584876777  Weight:  -1.992271683469254\n",
            "Error:  -0.023184949592238047  Weight:  -1.992967231957021\n",
            "Error:  -0.021098304128936585  Weight:  -1.993600181080889\n",
            "Error:  -0.019199456757333033  Weight:  -1.9941761647836087\n",
            "Error:  -0.017471505649173703  Weight:  -1.9947003099530838\n",
            "Error:  -0.015899070140748473  Weight:  -1.9951772820573062\n",
            "Error:  -0.014468153828081531  Weight:  -1.9956113266721487\n",
            "Error:  -0.013166019983553934  Weight:  -1.9960063072716554\n",
            "Error:  -0.0119810781850338  Weight:  -1.9963657396172063\n",
            "Error:  -0.010902781148381058  Weight:  -1.9966928230516579\n",
            "Error:  -0.00992153084502645  Weight:  -1.9969904689770086\n",
            "Error:  -0.009028593068974189  Weight:  -1.9972613267690777\n",
            "Error:  -0.008216019692766575  Weight:  -1.9975078073598607\n",
            "Error:  -0.007476577920418004  Weight:  -1.9977321046974732\n",
            "Error:  -0.006803685907580226  Weight:  -1.9979362152747004\n",
            "Error:  -0.006191354175898667  Weight:  -1.9981219558999774\n",
            "Error:  -0.005634132300067529  Weight:  -1.9982909798689794\n",
            "Error:  -0.005127060393061944  Weight:  -1.9984447916807713\n",
            "Error:  -0.0046656249576861875  Weight:  -1.998584760429502\n",
            "Error:  -0.004245718711493973  Weight:  -1.9987121319908467\n",
            "Error:  -0.003863604027459777  Weight:  -1.9988280401116707\n",
            "Error:  -0.0035158796649878976  Weight:  -1.9989335165016202\n",
            "Error:  -0.0031994504951395443  Weight:  -1.9990295000164744\n",
            "Error:  -0.0029114999505770013  Weight:  -1.9991168450149917\n",
            "Error:  -0.0026494649550250493  Weight:  -1.9991963289636423\n",
            "Error:  -0.0024110131090731013  Weight:  -1.9992686593569144\n",
            "Error:  -0.00219402192925684  Weight:  -1.9993344800147919\n",
            "Error:  -0.001996559955624244  Weight:  -1.9993943768134605\n",
            "Error:  -0.0018168695596183504  Weight:  -1.999448882900249\n",
            "Error:  -0.0016533512992527478  Weight:  -1.9994984834392264\n",
            "Error:  -0.0015045496823208992  Weight:  -1.999543619929696\n",
            "Error:  -0.0013691402109117234  Weight:  -1.9995846941360234\n",
            "Error:  -0.0012459175919299348  Weight:  -1.9996220716637816\n",
            "Error:  -0.0011337850086552415  Weight:  -1.9996560852140413\n",
            "Error:  -0.0010317443578762298  Weight:  -1.9996870375447775\n",
            "Error:  -0.0009388873656676732  Weight:  -1.9997152041657476\n",
            "Error:  -0.0008543875027573478  Weight:  -1.99974083579083\n",
            "Error:  -0.0007774926275101457  Weight:  -1.999764160569655\n",
            "Error:  -0.000707518291034992  Weight:  -1.999785386118386\n",
            "Error:  -0.000643841644841947  Weight:  -1.9998047013677314\n",
            "Error:  -0.0005858958968057327  Weight:  -1.9998222782446353\n",
            "Error:  -0.0005331652660938602  Weight:  -1.999838273202618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CON CLASES"
      ],
      "metadata": {
        "id": "S0hWSUeyYtMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(Y: list, X: list, forward_pass, fast : bool = False):\n",
        "  '''\n",
        "  Funcion de calculo de perdida\n",
        "  Params\n",
        "      Y-> resultado esperado\n",
        "      X -> input\n",
        "      forward_pass-> funcion de preiccion\n",
        "      fast-> cambia funcion de error\n",
        "  resultado\n",
        "      e-> error de la iteracion previa\n",
        "\n",
        "  '''\n",
        "  if fast:\n",
        "    s= sum([y-forward_pass(x)**3 for y,x in zip(Y,X)])\n",
        "  else:\n",
        "    #Esta funcion pemaliza mas los erroes altos\n",
        "    s= sum([y-forward_pass(x) for y,x in zip(Y,X)])\n",
        "  return s/len(X)"
      ],
      "metadata": {
        "id": "3xlq5EWFlGnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delta_rule(e : float, X : list, w : float, lr : float = 0.002 ):\n",
        "  '''\n",
        "  Regla optimización que actualiza w\n",
        "  Params\n",
        "      e-> error de la iteracion previa\n",
        "      X -> input\n",
        "      w-> peso de la iteracion pervia\n",
        "      lr-> learning rate\n",
        "  resultado\n",
        "      wt-> la nueva version de w\n",
        "\n",
        "  '''\n",
        "  for x in X:\n",
        "    w = w+lr*e*x\n",
        "  return w"
      ],
      "metadata": {
        "id": "24xFdGawlGRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "\n",
        "  def __init__(self,):\n",
        "    self.w = random.uniform(-1,1)\n",
        "    self.b = random.uniform(-1,1)\n",
        "\n",
        "  def compile(self,**kargs):\n",
        "    '''\n",
        "    Setea perdida, optimizacion ...\n",
        "    Params\n",
        "      loss -> funcion de perdida para evaluar el error\n",
        "      optimization -> funcion para actualizar el valor de pesos\n",
        "      lr -> learning rate\n",
        "\n",
        "    '''\n",
        "    self.loss = kargs.get(\"loss\")\n",
        "    self.optimization = kargs.get(\"optimization\")\n",
        "    self.lr = kargs.get(\"lr\")\n",
        "\n",
        "  def fit(self,**kargs):\n",
        "    '''\n",
        "    Hiperparametros del modelo\n",
        "    Params\n",
        "      x->input data\n",
        "      y->output data\n",
        "      epochs->iterations\n",
        "    '''\n",
        "\n",
        "    self.x = kargs.get(\"x\")\n",
        "    self.y = kargs.get(\"y\")\n",
        "    self.epochs = kargs.get(\"epochs\")\n",
        "\n",
        "  def train(self):\n",
        "    '''\n",
        "    Entrena los pesos\n",
        "    Param\n",
        "      None\n",
        "    return\n",
        "      historic -> diccionario con error y perdid\n",
        "    '''\n",
        "    historic={\"error\":[],\n",
        "              \"peso\":[],\n",
        "              \"accuracy\":[]\n",
        "              }\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      e = self.loss(self.y,self.x, self.predict)\n",
        "      self.w = self.optimization(e,self.x,self.w,self.lr)\n",
        "      historic[\"error\"].append(e)\n",
        "      historic[\"peso\"].append(self.w)\n",
        "      historic[\"accuracy\"].append(1-(e/sum(self.y)))\n",
        "    return historic\n",
        "\n",
        "  def predict(self,input):\n",
        "    return input*self.w"
      ],
      "metadata": {
        "id": "nAZ7s0ksM-QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1,2,3,4,5]\n",
        "outputs = [-2,-4,-6,-8,-10]\n",
        "\n",
        "neuron = Neuron()\n",
        "neuron.compile(loss=loss,optimization=delta_rule,lr=0.0022)\n",
        "neuron.fit(x=inputs,y=outputs,epochs = 100)\n",
        "hist = neuron.train()\n",
        "for e,p,a in zip(hist['error'],hist['peso'],hist['accuracy']):\n",
        "  print('Error: ',e,' Peso: ',p, 'Accuracy: ',a)\n"
      ],
      "metadata": {
        "id": "P2LkV1Owmtxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81409960-8550-4f83-9bd1-ee812e310e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  -7.39097752615379  Peso:  0.2197569170215216 Accuracy:  0.7536340824615403\n",
            "Error:  -6.6592707510645655  Peso:  9.822363909173237e-07 Accuracy:  0.7780243082978479\n",
            "Error:  -6.000002946709172  Peso:  -0.19799911500501177 Accuracy:  0.7999999017763609\n",
            "Error:  -5.406002654984965  Peso:  -0.37639720261951565 Accuracy:  0.8197999115005011\n",
            "Error:  -4.870808392141454  Peso:  -0.5371338795601837 Accuracy:  0.8376397202619515\n",
            "Error:  -4.388598361319449  Peso:  -0.6819576254837255 Accuracy:  0.8537133879560184\n",
            "Error:  -3.954127123548824  Peso:  -0.8124438205608367 Accuracy:  0.8681957625483725\n",
            "Error:  -3.56266853831749  Peso:  -0.9300118823253138 Accuracy:  0.8812443820560837\n",
            "Error:  -3.2099643530240582  Peso:  -1.0359407059751078 Accuracy:  0.8930011882325314\n",
            "Error:  -2.8921778820746766  Peso:  -1.1313825760835723 Accuracy:  0.9035940705975107\n",
            "Error:  -2.605852271749283  Peso:  -1.2173757010512987 Accuracy:  0.9131382576083572\n",
            "Error:  -2.3478728968461042  Peso:  -1.29485550664722 Accuracy:  0.9217375701051298\n",
            "Error:  -2.11543348005834  Peso:  -1.3646648114891453 Accuracy:  0.9294855506647219\n",
            "Error:  -1.906005565532564  Peso:  -1.42756299515172 Accuracy:  0.9364664811489145\n",
            "Error:  -1.7173110145448405  Peso:  -1.4842342586316994 Accuracy:  0.942756299515172\n",
            "Error:  -1.5472972241049017  Peso:  -1.5352950670271615 Accuracy:  0.94842342586317\n",
            "Error:  -1.3941147989185156  Peso:  -1.5813008553914722 Accuracy:  0.9535295067027162\n",
            "Error:  -1.2560974338255833  Peso:  -1.6227520707077163 Accuracy:  0.9581300855391472\n",
            "Error:  -1.1317437878768513  Peso:  -1.6600996157076524 Accuracy:  0.9622752070707716\n",
            "Error:  -1.019701152877043  Peso:  -1.693749753752595 Accuracy:  0.9660099615707652\n",
            "Error:  -0.9187507387422151  Peso:  -1.7240685281310881 Accuracy:  0.9693749753752595\n",
            "Error:  -0.8277944156067356  Peso:  -1.7513857438461107 Accuracy:  0.9724068528131088\n",
            "Error:  -0.7458427684616682  Peso:  -1.7759985552053454 Accuracy:  0.975138574384611\n",
            "Error:  -0.6720043343839637  Peso:  -1.7981746982400164 Accuracy:  0.9775998555205345\n",
            "Error:  -0.6054759052799508  Peso:  -1.8181554031142548 Accuracy:  0.9798174698240016\n",
            "Error:  -0.5455337906572357  Peso:  -1.8361580182059436 Accuracy:  0.9818155403114255\n",
            "Error:  -0.49152594538216937  Peso:  -1.8523783744035551 Accuracy:  0.9836158018205944\n",
            "Error:  -0.4428648767893346  Peso:  -1.8669929153376033 Accuracy:  0.9852378374403555\n",
            "Error:  -0.39902125398719024  Peso:  -1.8801606167191804 Accuracy:  0.9866992915337603\n",
            "Error:  -0.35951814984245883  Peso:  -1.8920247156639818 Accuracy:  0.988016061671918\n",
            "Error:  -0.32392585300805465  Peso:  -1.9027142688132475 Accuracy:  0.9892024715663982\n",
            "Error:  -0.29185719356025763  Peso:  -1.9123455562007359 Accuracy:  0.9902714268813247\n",
            "Error:  -0.2629633313977924  Peso:  -1.9210233461368629 Accuracy:  0.9912345556200736\n",
            "Error:  -0.23692996158941154  Peso:  -1.9288420348693134 Accuracy:  0.9921023346136862\n",
            "Error:  -0.21347389539205985  Peso:  -1.9358866734172513 Accuracy:  0.9928842034869313\n",
            "Error:  -0.19233997974824613  Peso:  -1.9422338927489433 Accuracy:  0.9935886673417251\n",
            "Error:  -0.1732983217531699  Peso:  -1.947952737366798 Accuracy:  0.9942233892748943\n",
            "Error:  -0.15614178789960592  Peso:  -1.953105416367485 Accuracy:  0.9947952737366798\n",
            "Error:  -0.1406837508975451  Peso:  -1.957747980147104 Accuracy:  0.9953105416367485\n",
            "Error:  -0.12675605955868802  Peso:  -1.9619309301125407 Accuracy:  0.9957747980147104\n",
            "Error:  -0.11420720966237767  Peso:  -1.9656997680313992 Accuracy:  0.996193093011254\n",
            "Error:  -0.10290069590580231  Peso:  -1.9690954909962908 Accuracy:  0.99656997680314\n",
            "Error:  -0.09271352701112767  Peso:  -1.9721550373876582 Accuracy:  0.996909549099629\n",
            "Error:  -0.08353488783702545  Peso:  -1.97491168868628 Accuracy:  0.9972155037387658\n",
            "Error:  -0.07526493394115974  Peso:  -1.9773954315063382 Accuracy:  0.997491168868628\n",
            "Error:  -0.06781370548098531  Peso:  -1.979633283787211 Accuracy:  0.9977395431506338\n",
            "Error:  -0.06110014863836688  Peso:  -1.981649588692277 Accuracy:  0.9979633283787211\n",
            "Error:  -0.05505123392316924  Peso:  -1.9834662794117417 Accuracy:  0.9981649588692277\n",
            "Error:  -0.049601161764774915  Peso:  -1.9851031177499792 Accuracy:  0.9983466279411741\n",
            "Error:  -0.04469064675006251  Peso:  -1.9865779090927311 Accuracy:  0.9985103117749979\n",
            "Error:  -0.040266272721806606  Peso:  -1.9879066960925507 Accuracy:  0.9986577909092731\n",
            "Error:  -0.03627991172234801  Peso:  -1.989103933179388 Accuracy:  0.9987906696092551\n",
            "Error:  -0.03268820046183585  Peso:  -1.9901826437946288 Accuracy:  0.9989103933179388\n",
            "Error:  -0.02945206861611367  Peso:  -1.9911545620589606 Accuracy:  0.9990182643794628\n",
            "Error:  -0.026536313823118274  Peso:  -1.9920302604151234 Accuracy:  0.999115456205896\n",
            "Error:  -0.023909218754629702  Peso:  -1.9928192646340264 Accuracy:  0.9992030260415123\n",
            "Error:  -0.021542206097920902  Peso:  -1.9935301574352577 Accuracy:  0.9992819264634026\n",
            "Error:  -0.019409527694226592  Peso:  -1.9941706718491674 Accuracy:  0.9993530157435258\n",
            "Error:  -0.017487984452497773  Peso:  -1.9947477753360998 Accuracy:  0.9994170671849167\n",
            "Error:  -0.015756673991700377  Peso:  -1.995267745577826 Accuracy:  0.99947477753361\n",
            "Error:  -0.014196763266521861  Peso:  -1.9957362387656212 Accuracy:  0.9995267745577826\n",
            "Error:  -0.01279128370313649  Peso:  -1.996158351127825 Accuracy:  0.9995736238765621\n",
            "Error:  -0.011524946616525256  Peso:  -1.9965386743661702 Accuracy:  0.9996158351127825\n",
            "Error:  -0.010383976901489334  Peso:  -1.9968813456039194 Accuracy:  0.999653867436617\n",
            "Error:  -0.009355963188241834  Peso:  -1.9971900923891315 Accuracy:  0.999688134560392\n",
            "Error:  -0.008429722832605568  Peso:  -1.9974682732426072 Accuracy:  0.9997190092389131\n",
            "Error:  -0.007595180272178315  Peso:  -1.9977189141915894 Accuracy:  0.9997468273242607\n",
            "Error:  -0.00684325742523173  Peso:  -1.997944741686622 Accuracy:  0.9997718914191589\n",
            "Error:  -0.006165774940133639  Peso:  -1.9981482122596463 Accuracy:  0.9997944741686622\n",
            "Error:  -0.005555363221060983  Peso:  -1.9983315392459413 Accuracy:  0.9998148212259647\n",
            "Error:  -0.005005382262176061  Peso:  -1.9984967168605932 Accuracy:  0.9998331539245942\n",
            "Error:  -0.004509849418220702  Peso:  -1.9986455418913944 Accuracy:  0.9998496716860593\n",
            "Error:  -0.004063374325816715  Peso:  -1.9987796332441463 Accuracy:  0.9998645541891394\n",
            "Error:  -0.003661100267561057  Peso:  -1.9989004495529759 Accuracy:  0.9998779633244146\n",
            "Error:  -0.003298651341072434  Peso:  -1.999009305047231 Accuracy:  0.9998900449552975\n",
            "Error:  -0.0029720848583068005  Peso:  -1.9991073838475553 Accuracy:  0.9999009305047231\n",
            "Error:  -0.002677848457334031  Peso:  -1.9991957528466473 Accuracy:  0.9999107383847555\n",
            "Error:  -0.0024127414600582766  Peso:  -1.9992753733148292 Accuracy:  0.9999195752846647\n",
            "Error:  -0.002173880055512445  Peso:  -1.9993471113566608 Accuracy:  0.9999275373314829\n",
            "Error:  -0.001958665930017878  Peso:  -1.9994117473323514 Accuracy:  0.9999347111356661\n",
            "Error:  -0.0017647580029458432  Peso:  -1.9994699843464485 Accuracy:  0.9999411747332352\n",
            "Error:  -0.0015900469606544565  Peso:  -1.9995224558961504 Accuracy:  0.9999469984346449\n",
            "Error:  -0.001432632311548776  Peso:  -1.9995697327624316 Accuracy:  0.999952245589615\n",
            "Error:  -0.0012908017127051697  Peso:  -1.9996123292189507 Accuracy:  0.9999569732762431\n",
            "Error:  -0.0011630123431476847  Peso:  -1.9996507086262743 Accuracy:  0.9999612329218951\n",
            "Error:  -0.001047874121177239  Peso:  -1.9996852884722731 Accuracy:  0.9999650708626274\n",
            "Error:  -0.0009441345831806558  Peso:  -1.999716444913518 Accuracy:  0.9999685288472273\n",
            "Error:  -0.0008506652594457709  Peso:  -1.9997445168670798 Accuracy:  0.9999716444913518\n",
            "Error:  -0.0007664493987606935  Peso:  -1.999769809697239 Accuracy:  0.999974451686708\n",
            "Error:  -0.0006905709082831724  Peso:  -1.999792598537212 Accuracy:  0.9999769809697239\n",
            "Error:  -0.0006222043883639117  Peso:  -1.9998131312820278 Accuracy:  0.9999792598537212\n",
            "Error:  -0.0005606061539167317  Peso:  -1.9998316312851072 Accuracy:  0.9999813131282028\n",
            "Error:  -0.0005051061446781802  Peso:  -1.999848299787882 Accuracy:  0.9999831631285108\n",
            "Error:  -0.0004551006363540555  Peso:  -1.9998633181088816 Accuracy:  0.9999848299787882\n",
            "Error:  -0.00041004567335511943  Peso:  -1.9998768496161023 Accuracy:  0.9999863318108881\n",
            "Error:  -0.0003694511516929566  Peso:  -1.9998890415041082 Accuracy:  0.9999876849616103\n",
            "Error:  -0.0003328754876754658  Peso:  -1.9999000263952016 Accuracy:  0.9999889041504109\n",
            "Error:  -0.000299920814395227  Peso:  -1.9999099237820763 Accuracy:  0.9999900026395202\n",
            "Error:  -0.00027022865377084314  Peso:  -1.9999188413276507 Accuracy:  0.9999909923782077\n",
            "Error:  -0.00024347601704777233  Peso:  -1.9999268760362132 Accuracy:  0.9999918841327651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.predict(300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ5JKxxsGcfd",
        "outputId": "1813e114-cce4-45bc-971a-7af56b6df55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-599.978062810864"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Xug9phgjGACW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist['error'])\n",
        "plt.plot(hist['peso'])\n",
        "plt.plot(hist['accuracy'],'--g')\n",
        "\n",
        "plt.legend(hist.keys())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FySUcwFSqfhf",
        "outputId": "5cce7abe-043e-4a70-a313-fefedb0f9b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}